{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSPNET training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNs7BNP+BwMyAaGRwyWtViD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssnirgudkar/UNet/blob/main/PSPNET_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46CYBSNeExMa"
      },
      "source": [
        "!git clone https://github.com/divamgupta/image-segmentation-keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3JQk1XEXGkT"
      },
      "source": [
        "cd image-segmentation-keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SDAkn_iXIDk"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdV6CtyYXnkr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yzUdQ8JZFV2"
      },
      "source": [
        "!pip install --upgrade git+https://github.com/divamgupta/image-segmentation-keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tpQXZvpZrxD"
      },
      "source": [
        "!pip uninstall keras -y\n",
        "!pip uninstall keras-nightly -y\n",
        "!pip uninstall keras-Preprocessing -y\n",
        "!pip uninstall keras-vis -y\n",
        "!pip uninstall tensorflow -y\n",
        "#!pip uninstall h5py -y\n",
        "\n",
        "!pip install tensorflow==2.4.1\n",
        "!pip install keras==2.4.3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb1QRo26XyQH"
      },
      "source": [
        "#create a model skeleton for pspnet model. images need to be a multiple of 192\n",
        "from keras_segmentation.models.pspnet import pspnet\n",
        "\n",
        "model= pspnet(n_classes =3, input_height=384, input_width=576, channels=3) # load the pretrained model trained on Cityscapes dataset\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "1HFZnNiosDwq",
        "outputId": "f11da9f8-f590-4f13-8890-ab8d5e12a984"
      },
      "source": [
        "''' loading weights throws an error\n",
        "model.train(\n",
        "    train_images =  \"/content/drive/MyDrive/psp-images/\",\n",
        "    train_annotations = \"/content/drive/MyDrive/psp-seg-images\",\n",
        "    checkpoints_path = \"/content/drive/MyDrive/Models/pspnet/\" , epochs=2,\n",
        "    load_weights=\"/content/drive/MyDrive/Models/pspnet/pspnet101_cityscapes.h5\"  \n",
        ")\n",
        "'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights from  /content/drive/MyDrive/Models/pspnet/pspnet101_cityscapes.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6d34123fecf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/psp-seg-images\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcheckpoints_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Models/pspnet/\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mload_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Models/pspnet/pspnet101_cityscapes.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_segmentation-0.3.0-py3.7.egg/keras_segmentation/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_images, train_annotations, input_height, input_width, n_classes, verify_dataset, checkpoints_path, epochs, batch_size, validate, val_images, val_annotations, val_batch_size, auto_resume_checkpoint, load_weights, steps_per_epoch, val_steps_per_epoch, gen_use_multiprocessing, ignore_zero_class, optimizer_name, do_augment, augmentation_name, callbacks, custom_augmentation, other_inputs_paths, preprocessing, read_image_type)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mload_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   2233\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    686\u001b[0m                      \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                      \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m                      ' layers.')\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m   \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 223 layers into a model with 21 layers."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plhne2AZaanv"
      },
      "source": [
        "'''\n",
        "# load any of the 3 pretrained models - for direct inference\n",
        "\n",
        "from keras_segmentation.pretrained import pspnet_101_cityscapes \n",
        "model = pspnet_101_cityscapes()\n",
        "'''\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tMMjw_NOTnI"
      },
      "source": [
        "# for training 1st time without weights\n",
        "model.train(\n",
        "    train_images =  \"/content/drive/MyDrive/psp-images/\",\n",
        "    train_annotations = \"/content/drive/MyDrive/psp-seg-images\",\n",
        "    checkpoints_path = \"/content/drive/MyDrive/Models/pspnet/\" , epochs=2\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F69M_aZqQ_oD"
      },
      "source": [
        "#save weights so that we can use it during next training \n",
        "model.save('/content/drive/MyDrive/Models/pspnet/pspnet_train_model.h5')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZEY5IqrSHL4"
      },
      "source": [
        "\"\"\"\n",
        "#this is for infering w/o retraining. just take weights and use it\n",
        "from keras_segmentation.models.pspnet import pspnet\n",
        "model1= pspnet(n_classes =3, input_height=384, input_width=576, channels=3) # load the pretrained model trained on Cityscapes dataset\n",
        "\n",
        "from keras.models import load_model\n",
        "model1 = load_model('/content/drive/MyDrive/Models/pspnet/pspnet_train_model.h5')\n",
        "\n",
        "out = model1.predict_segmentation(\n",
        "    inp=\"/content/drive/MyDrive/psp-images/1571161258.414889.png\",\n",
        "    out_fname=\"/content/out1.png\"\n",
        ")\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(out)\n",
        "\"\"\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8XTLOL5SYOC"
      },
      "source": [
        "# this is to train from 2nd time on, using earlier weights\n",
        "model.train(\n",
        "    train_images =  \"/content/drive/MyDrive/psp-images/\",\n",
        "    train_annotations = \"/content/drive/MyDrive/psp-seg-images\",\n",
        "    checkpoints_path = \"/content/drive/MyDrive/Models/pspnet/\" , epochs=2,\n",
        "    load_weights=\"/content/drive/MyDrive/Models/pspnet/pspnet_train_model.h5\"  \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWoSQTFuM-Hh"
      },
      "source": [
        "# this is to infer based on the training. With gpu it gives blank.  \n",
        "out = model.predict_segmentation(\n",
        "    inp=\"/content/drive/MyDrive/psp-images/1571161174.581624.png\",\n",
        "    out_fname=\"/content/out1.png\"\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "X0RkQao2or2f",
        "outputId": "ac727a83-3aa1-4787-f145-a44a28c6a574"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(out)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5b0678a750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "QfJK29Vfo_3C",
        "outputId": "7f6ace57-2884-44e5-861d-9f3c649d4a70"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('/content/out.png')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "/content/out.png",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KixJsN4ygSgR"
      },
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "imageDir = r'/content/drive/MyDrive/IRImageTrainingDataset/ir_train_images_resized_colored_291_images'\n",
        "resizedImageDir = '/content/resize'\n",
        "for file in os.listdir(imageDir):\n",
        "    f_img = imageDir + \"/\" + file\n",
        "    resized_img = resizedImageDir + \"/\" + file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((384,576))\n",
        "    img.save(resized_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDNgy9mljtCU"
      },
      "source": [
        "maskDir = r'/content/drive/MyDrive/IRImageTrainingDataset/ir_train_masks_resized_relabeled_291_images'\n",
        "resizedMaskDir = '/content/resize-annot'\n",
        "for file in os.listdir(maskDir):\n",
        "    f_img = maskDir + \"/\" + file\n",
        "    resized_img = resizedMaskDir + \"/\" + file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((384,576))\n",
        "    img.save(resized_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-s36vE-caTH"
      },
      "source": [
        "from keras_segmentation.models.pspnet import pspnet\n",
        "\n",
        "model = pspnet(n_classes=3, input_height=384, input_width=576  )\n",
        "\n",
        "model.train(\n",
        "    train_images =  \"/content/drive/MyDrive/psp-images\",\n",
        "    train_annotations = \"/content/drive/MyDrive/psp-seg-images\",\n",
        "    input_height=384,\n",
        "    input_width=576,\n",
        "    checkpoints_path = \"/content/drive/MyDrive/Models/pspnet/pspnet_1\", \n",
        "    epochs=2\n",
        "    \n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbOv-DSWdF_o"
      },
      "source": [
        "\n",
        "out = model.predict_segmentation(\n",
        "    inp=\"/content/drive/MyDrive/psp-images/1571161174.581624.png\",\n",
        "    out_fname=\"/content/drive/MyDrive/psp-images/seg.png\"\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR859gwIGhlY",
        "outputId": "6e11144f-8242-418b-b789-7d2c85ec31f8"
      },
      "source": [
        "import cv2\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import PIL\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/psp-images/seg.png', cv2.IMREAD_UNCHANGED)\n",
        "print(img.shape) # height , width, color\n",
        "array1 = tensorflow.keras.preprocessing.image.img_to_array(img)\n",
        "print(array1) \n",
        "print(np.unique(array1))\n",
        "\n",
        "#print(np.unique(cv2.imread('/content/drive/MyDrive/IRImageTrainingDataset/ir_train_masks_resized_relabeled_291_images/1571161174.581624_label_ground-truth_resized_relabeled_to3wasrclasses_mirrored.png',cv2.IMREAD_UNCHANGED)))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(576, 384, 3)\n",
            "[[[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]\n",
            "\n",
            " [[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]\n",
            "\n",
            " [[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]\n",
            "\n",
            " [[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]\n",
            "\n",
            " [[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]]\n",
            "[ 20. 197. 215.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6P3HdHFDpfL",
        "outputId": "66d08105-1990-497e-ec1e-1661ca22213d"
      },
      "source": [
        "# evaluating the model \n",
        "print(model.evaluate_segmentation( inp_images_dir=\"/content/drive/MyDrive/psp-images/\"  , annotations_dir=\"/content/drive/MyDrive/psp-seg-images/\" ) )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6it [00:03,  1.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'frequency_weighted_IU': 1.0, 'mean_IU': 0.3333333333333333, 'class_wise_IU': array([1., 0., 0.])}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}