{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSPNET training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgjN+5C1E70e9OfUL4kzYq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssnirgudkar/UNet/blob/main/PSPNET_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46CYBSNeExMa"
      },
      "source": [
        "#!git clone https://github.com/divamgupta/image-segmentation-keras\n",
        "!git clone https://github.com/faysal-ishtiaq/image-segmentation-keras-py3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3JQk1XEXGkT"
      },
      "source": [
        "!cd image-segmentation-keras/keras_segmentation\n",
        " \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SDAkn_iXIDk"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdV6CtyYXnkr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b3b756-6b19-4942-d7ea-82e015629442"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yzUdQ8JZFV2"
      },
      "source": [
        "!pip install --upgrade git+https://github.com/divamgupta/image-segmentation-keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tpQXZvpZrxD"
      },
      "source": [
        "!pip uninstall keras -y\n",
        "!pip uninstall keras-nightly -y\n",
        "!pip uninstall keras-Preprocessing -y\n",
        "!pip uninstall keras-vis -y\n",
        "!pip uninstall tensorflow -y\n",
        "#!pip uninstall h5py -y\n",
        "\n",
        "!pip install tensorflow==2.4.1\n",
        "!pip install keras==2.4.3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ek-gHcuUFfx"
      },
      "source": [
        "!pip uninstall tensorflow tensorboard tensorboard-data-server tensorflow-datasets tensorflow-estimator tensorflow-gcs-config tensorflow-hub tensorflow-metadata tensorflow-probability keras keras-nightly Keras-Preprocessing keras-vis -y\n",
        "!pip install tensorflow==2.4\n",
        "!pip install git+https://github.com/divamgupta/image-segmentation-keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnUpZLPZKVpf"
      },
      "source": [
        "import keras\n",
        "from keras.models import model_from_json\n",
        "import keras_segmentation as ks\n",
        "from keras_segmentation import models  \n",
        "from keras_segmentation.models import pspnet\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb1QRo26XyQH"
      },
      "source": [
        "#create a model skeleton for pspnet model. images need to be a multiple of 192\n",
        "from keras_segmentation.models.pspnet import vgg_pspnet\n",
        "\n",
        "model= vgg_pspnet(n_classes =3, input_height=384, input_width=576, channels=3) # load the pretrained model trained on Cityscapes dataset\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HFZnNiosDwq"
      },
      "source": [
        "''' loading weights throws an error\n",
        "model.train(\n",
        "    train_images =  \"/content/drive/MyDrive/psp-images/\",\n",
        "    train_annotations = \"/content/drive/MyDrive/psp-seg-images\",\n",
        "    checkpoints_path = \"/content/drive/MyDrive/Models/pspnet/\" , epochs=2,\n",
        "    load_weights=\"/content/drive/MyDrive/Models/pspnet/pspnet101_cityscapes.h5\"  \n",
        ")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plhne2AZaanv"
      },
      "source": [
        "'''\n",
        "# load any of the 3 pretrained models - for direct inference\n",
        "\n",
        "from keras_segmentation.pretrained import pspnet_101_cityscapes \n",
        "model = pspnet_101_cityscapes()\n",
        "'''\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tMMjw_NOTnI"
      },
      "source": [
        "# for training 1st time without weights\n",
        "model.train(\n",
        "    train_images =  \"/content/drive/MyDrive/IRImages_3classes_PSPNet\",\n",
        "    train_annotations = \"/content/drive/MyDrive/IRImageMasks_3classes_PSPNet\",\n",
        "    checkpoints_path = \"/content/drive/MyDrive/Logs/pspnet\" , epochs=10, batch_size = 10,steps_per_epoch = 90, val_steps_per_epoch = 10\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F69M_aZqQ_oD"
      },
      "source": [
        "#save weights so that we can use it during next training \n",
        "model.save('/content/drive/MyDrive/Models/pspnet/pspnet_train_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZEY5IqrSHL4"
      },
      "source": [
        "\"\"\"\n",
        "#this is for infering w/o retraining. just take weights and use it\n",
        "from keras_segmentation.models.pspnet import pspnet\n",
        "model1= pspnet(n_classes =3, input_height=384, input_width=576, channels=3) # load the pretrained model trained on Cityscapes dataset\n",
        "\n",
        "from keras.models import load_model\n",
        "model1 = load_model('/content/drive/MyDrive/Models/pspnet/pspnet_train_model.h5')\n",
        "\n",
        "out = model1.predict_segmentation(\n",
        "    inp=\"/content/drive/MyDrive/psp-images/1571161258.414889.png\",\n",
        "    out_fname=\"/content/out1.png\"\n",
        ")\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(out)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8XTLOL5SYOC"
      },
      "source": [
        "# this is to train from 2nd time on, using earlier weights\n",
        "model.train(\n",
        "    train_images =  \"/content/drive/MyDrive/psp-images/\",\n",
        "    train_annotations = \"/content/drive/MyDrive/psp-seg-images\",\n",
        "    checkpoints_path = \"/content/drive/MyDrive/Models/pspnet/\" , epochs=2,\n",
        "    load_weights=\"/content/drive/MyDrive/Models/pspnet/pspnet_train_model.h5\"  \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWoSQTFuM-Hh"
      },
      "source": [
        "# this is to infer based on the training. With gpu it gives blank.  \n",
        "out = model.predict_segmentation(\n",
        "    inp=\"/content/drive/MyDrive/IRImages_3classes_PSPNet/1571161174.581624_1.png\",\n",
        "    out_fname=\"/content/out1.png\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "X0RkQao2or2f",
        "outputId": "658f7568-cb45-4aea-ef9d-675f13202f07"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1002072690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "QfJK29Vfo_3C",
        "outputId": "cd62d6be-c386-4e45-9cc5-2599e4bd3d84"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('/content/out1.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KixJsN4ygSgR"
      },
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "imageDir = r'/content/drive/MyDrive/IRImageTrainingDataset/ir_train_images_resized_colored_291_images'\n",
        "resizedImageDir = '/content/resize'\n",
        "for file in os.listdir(imageDir):\n",
        "    f_img = imageDir + \"/\" + file\n",
        "    resized_img = resizedImageDir + \"/\" + file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((384,576))\n",
        "    img.save(resized_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDNgy9mljtCU"
      },
      "source": [
        "maskDir = r'/content/drive/MyDrive/IRImageTrainingDataset/ir_train_masks_resized_relabeled_291_images'\n",
        "resizedMaskDir = '/content/resize-annot'\n",
        "for file in os.listdir(maskDir):\n",
        "    f_img = maskDir + \"/\" + file\n",
        "    resized_img = resizedMaskDir + \"/\" + file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((384,576))\n",
        "    img.save(resized_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-s36vE-caTH"
      },
      "source": [
        "from keras_segmentation.models.pspnet import pspnet\n",
        "\n",
        "model = pspnet(n_classes=3, input_height=384, input_width=576  )\n",
        "\n",
        "model.train(\n",
        "    train_images =  \"/content/drive/MyDrive/psp-images\",\n",
        "    train_annotations = \"/content/drive/MyDrive/psp-seg-images\",\n",
        "    input_height=384,\n",
        "    input_width=576,\n",
        "    checkpoints_path = \"/content/drive/MyDrive/Models/pspnet/pspnet_1\", \n",
        "    epochs=2\n",
        "    \n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbOv-DSWdF_o"
      },
      "source": [
        "\n",
        "out = model.predict_segmentation(\n",
        "    inp=\"/content/drive/MyDrive/psp-images/1571161174.581624.png\",\n",
        "    out_fname=\"/content/drive/MyDrive/psp-images/seg.png\"\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR859gwIGhlY",
        "outputId": "7b6564ac-fbd2-4b43-8c43-c67c29a64666"
      },
      "source": [
        "import cv2\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import PIL\n",
        "\n",
        "img = cv2.imread('/content/out1.png', cv2.IMREAD_UNCHANGED)\n",
        "print(img.shape) # height , width, color\n",
        "array1 = tensorflow.keras.preprocessing.image.img_to_array(img)\n",
        "print(array1) \n",
        "print(np.unique(array1))\n",
        "\n",
        "#print(np.unique(cv2.imread('/content/drive/MyDrive/IRImageTrainingDataset/ir_train_masks_resized_relabeled_291_images/1571161174.581624_label_ground-truth_resized_relabeled_to3wasrclasses_mirrored.png',cv2.IMREAD_UNCHANGED)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(384, 576, 3)\n",
            "[[[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]\n",
            "\n",
            " [[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]\n",
            "\n",
            " [[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]\n",
            "\n",
            " [[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]\n",
            "\n",
            " [[197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  ...\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]\n",
            "  [197. 215.  20.]]]\n",
            "[ 20. 197. 215.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6P3HdHFDpfL",
        "outputId": "66d08105-1990-497e-ec1e-1661ca22213d"
      },
      "source": [
        "# evaluating the model \n",
        "print(model.evaluate_segmentation( inp_images_dir=\"/content/drive/MyDrive/psp-images/\"  , annotations_dir=\"/content/drive/MyDrive/psp-seg-images/\" ) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6it [00:03,  1.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'frequency_weighted_IU': 1.0, 'mean_IU': 0.3333333333333333, 'class_wise_IU': array([1., 0., 0.])}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}